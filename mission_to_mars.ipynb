{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mac Users Chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/chromedriver\n"
     ]
    }
   ],
   "source": [
    "!which chromedriver\n",
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1 Mars NASA Latest News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# URL set up (Mars)\n",
    "mars_b = 'https://mars.nasa.gov/news/'\n",
    "# response = requests.get(mars) #the soup way\n",
    "browser.visit(mars_b)\n",
    "html = browser.html\n",
    "\n",
    "###NOTES:\n",
    "#For some reason, \"mars_url\" renders something else and won't let me retrieve the latest headline. The headline it retrieves is from 2/11/2020. And other url names that are already taken. If re-running the cell, the variable is taken and does something else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BeautifulSoup\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MarCO Mission Comes to an End: <div class=\"article_teaser_body\">The pair of briefcase-sized satellites made history when they sailed past Mars in 2019.</div>\n"
     ]
    }
   ],
   "source": [
    "#1 Collect the latest News Title and Paragraph Text\n",
    "news_title = soup.find('div', class_=\"content_title\").text\n",
    "news_par = soup.find('div', class_=\"article_teaser_body\")\n",
    "print(f'{news_title}: {news_par}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 JPL Mars Space Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL  set up (Mars space images)\n",
    "featured_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(featured_url)\n",
    "html_img = browser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_soup = bs(html_img, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_soup_img = img_soup.find(class_='carousel_item')[\"style\"]\n",
    "base_img_url = 'https://www.jpl.nasa.gov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_img_url = base_img_url + img_soup_img.strip('background-image: url').strip(\";(')\") #Getting rid of unnecessary characters and concatenating the base url\n",
    "print(featured_img_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 Mars Twitter Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL set up (Twit weather)\n",
    "m_tweets = 'https://twitter.com/marswxreport?lang=en'\n",
    "m_response = requests.get(m_tweets).text\n",
    "mars_tweets_soup = bs(m_response, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_weather = mars_tweets_soup.find('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text.strip('pic.twitter.com/ihFGVkib6L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mars_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4 Mars Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Mars Facts \n",
    "mars_facts_url = 'https://space-facts.com/mars/'\n",
    "tables = pd.read_html(mars_facts_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_table_facts = tables[0]\n",
    "mars_table_facts = pd.DataFrame(mars_table_facts)\n",
    "mars_table_facts = mars_table_facts.rename(columns={0: \"Description\", 1: \"Value\"}).set_index(\"Description\")\n",
    "mars_table_html = mars_table_facts.to_html(index=False).replace('\\n', '')\n",
    "mars_table_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_table_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5 Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#URL set up Mars Hemispheres\n",
    "hem_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "hem_base_url = 'https://astrogeology.usgs.gov'\n",
    "browser.visit(hem_url)\n",
    "hem_html = browser.html\n",
    "hem_soup = bs(hem_html, 'html.parser')\n",
    "hem_links = hem_soup.find_all('div', class_='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls = []\n",
    "\n",
    "for links in hem_links:\n",
    "    \n",
    "    #Links\n",
    "    #Concat links for image pages\n",
    "    img_urls = hem_base_url + links.find(\"a\", class_=\"itemLink product-item\")['href']\n",
    "    #Soup again\n",
    "    browser.visit(img_urls)\n",
    "    img_urls_html = browser.html\n",
    "    loop_soup = bs(img_urls_html, 'html.parser')\n",
    "    #Finding the links for the FULL DOWNLOAD image (index find_all('li')[1] if the full-quality res is wanted, default [0] gives the lower quality image but more page friendly, but img and wide-image gives smaller images too)\n",
    "    loop_links = loop_soup.find(\"img\", class_=\"wide-image\")['src']\n",
    "    loopy_links = hem_base_url + loop_links\n",
    "    \n",
    "    #Title\n",
    "    title = links.find(\"h3\").text\n",
    "    \n",
    "    #Append\n",
    "    hemisphere_image_urls.append({\"title\":title, \"img_url\": loopy_links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script 'mission_to_mars.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
